{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1197638e-ccfd-4b12-8877-fa72e64fcbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "messages = pd.read_csv('Data/smsspamclassification',sep='\\t',names=['label','message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1affd0d8-415e-4127-a104-076f6ad22218",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to C:\\Users\\Pavilion\\OneDriv\n",
      "[nltk_data]     e\\Desktop\\UdemyMLCourse\\venv\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36db8ba5-6a17-4efc-8a30-b03eca359cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "ps =PorterStemmer()\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1259071a-7397-4bd3-a952-2304f4e04949",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(0,len(messages)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',messages['message'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    review = [wl.lemmatize(word,pos='v') for word in review if not word in stopwords.words('english')]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb539ad6-cede-4c59-b89c-661d02953080",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.get_dummies(messages['label']).astype('int')\n",
    "y = y.iloc[:,0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90570cd9-8a81-40fa-b94c-f20c54599b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(corpus,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14229739-c5ec-4fff-aabf-9974f29e1cc6",
   "metadata": {},
   "source": [
    "# Bag Of Word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0678486d-5f39-49fe-a127-5c488dd3ea8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Create the bag of word model\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# For binary Bag of word make sure the parameter binary=True\n",
    "cv = CountVectorizer(max_features=2500, binary=True) # Out of all word in the dataset take 2500 words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "845b4403-1c4d-4214-a948-3184471fa360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4457"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3df2987f-5747-4f63-8ce9-24558cb69320",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4457,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fc49304-c998-49d2-b75a-ff66d4742142",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = cv.fit_transform(X_train).toarray()\n",
    "X_test_transformed = cv.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5992f347-c589-486e-a7b8-0abcbc328bf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_transformed.ndim "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0a4fe826-7a89-464b-b9f8-cc0c5061bc82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.39\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.93      0.94       149\n",
      "           1       0.99      0.99      0.99       966\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.97      0.96      0.96      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "spam_detect_model = MultinomialNB().fit(X_train_transformed, y_train)\n",
    "y_preds = spam_detect_model.predict(X_test_transformed)\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_preds)*100:.2f}\")\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddca02d9-554d-4d45-874c-38e942bfb361",
   "metadata": {},
   "source": [
    "# TF-IDF "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a328f8c0-78a8-4427-a54c-5f92b81e3e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(max_features=2500,ngram_range=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68e738d2-6199-44c0-b6fb-5f42411ee70e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_transformed = tfidf.fit_transform(X_train).toarray()\n",
    "X_test_transformed = tfidf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fbc483e2-ceb9-494b-81d1-5c54e425f52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 97.94\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.85      0.92       149\n",
      "           1       0.98      1.00      0.99       966\n",
      "\n",
      "    accuracy                           0.98      1115\n",
      "   macro avg       0.98      0.93      0.95      1115\n",
      "weighted avg       0.98      0.98      0.98      1115\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "spam_detect_model = MultinomialNB().fit(X_train_transformed, y_train)\n",
    "y_preds = spam_detect_model.predict(X_test_transformed)\n",
    "print(f\"Accuracy: {accuracy_score(y_test,y_preds)*100:.2f}\")\n",
    "print(classification_report(y_test,y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c82c28-8e4f-494e-9c36-3100232af350",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
