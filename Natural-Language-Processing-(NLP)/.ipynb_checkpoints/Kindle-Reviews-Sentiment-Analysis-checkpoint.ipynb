{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6d3c6f6b-b535-4c62-88c6-3fbb0518ffb8",
   "metadata": {},
   "source": [
    "# ***KINDLE REVIEW SENTIMENT ANALYSIS***\n",
    "## **About Dataset**\n",
    "Context: This is a subset of dataset of book reviews from kindle store category.\n",
    "\n",
    "**Content** \n",
    "* 5-crore dataset of product reviews from amazon jindle store category from May 1996 - july 2014. Contans total of 98260 entries. Each product has at least 5 reviews in the dataset.\n",
    "\n",
    "**Columns**\n",
    "* `asin` - ID of the product, like B000FA64PK\n",
    "* `helpful` - Helpful rating of the review - example 2/3\n",
    "* `overall` - Rating of the product.\n",
    "* `reviewText` -\n",
    "*  text of the review (heading).\n",
    "* `reviewTime` - time of the review (raw)\n",
    "* `reviewerID` - ID of the eeviewer, like A3SPTOKDG7WBLN\n",
    "* `reviewerName` - name of the reviewer.\n",
    "* `summary` - summary of thr reviwer\n",
    "* `unixReviewTime` - unix timestamp\n",
    "\n",
    "**Inspiration**\n",
    "- Sentimanet Analysis\n",
    "- Understanding how people rate usefulness of a review/ what factor influence helpfulness of a review.\n",
    "- Fake reviews/ outliers.\n",
    "- Best rated product IDs, or similarity between products based on review alone\n",
    "\n",
    "**Process**\n",
    "The dataset contans 11 columns. But in this project we only need Two columns  i.e.- `rating` and `reviewText` for sentiment analysis\t\n",
    "\n",
    "**Steps**\n",
    "1. Preprocessing and Cleaning\n",
    "2. Train Test Split\n",
    "3. Bag Of Words(BOW)/ Word2Vec\n",
    "4. Train with Machine Learning Algorithm\n",
    "5. Model Evaluation and Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ecba83a7-3045-420c-a871-7a72c0a6f146",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>asin</th>\n",
       "      <th>helpful</th>\n",
       "      <th>rating</th>\n",
       "      <th>reviewText</th>\n",
       "      <th>reviewTime</th>\n",
       "      <th>reviewerID</th>\n",
       "      <th>reviewerName</th>\n",
       "      <th>summary</th>\n",
       "      <th>unixReviewTime</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>11539</td>\n",
       "      <td>B0033UV8HI</td>\n",
       "      <td>[8, 10]</td>\n",
       "      <td>3</td>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>09 2, 2010</td>\n",
       "      <td>A3HHXRELK8BHQG</td>\n",
       "      <td>Ridley</td>\n",
       "      <td>Entertaining But Average</td>\n",
       "      <td>1283385600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5957</td>\n",
       "      <td>B002HJV4DE</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>5</td>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>10 8, 2013</td>\n",
       "      <td>A2RGNZ0TRF578I</td>\n",
       "      <td>Holly Butler</td>\n",
       "      <td>Terrific menage scenes!</td>\n",
       "      <td>1381190400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>9146</td>\n",
       "      <td>B002ZG96I4</td>\n",
       "      <td>[0, 0]</td>\n",
       "      <td>3</td>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>04 11, 2014</td>\n",
       "      <td>A3S0H2HV6U1I7F</td>\n",
       "      <td>Merissa</td>\n",
       "      <td>Snapdragon Alley</td>\n",
       "      <td>1397174400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>7038</td>\n",
       "      <td>B002QHWOEU</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>3</td>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>07 5, 2014</td>\n",
       "      <td>AC4OQW3GZ919J</td>\n",
       "      <td>Cleargrace</td>\n",
       "      <td>very light murder cozy</td>\n",
       "      <td>1404518400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1776</td>\n",
       "      <td>B001A06VJ8</td>\n",
       "      <td>[0, 1]</td>\n",
       "      <td>4</td>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>12 31, 2012</td>\n",
       "      <td>A3C9V987IQHOQD</td>\n",
       "      <td>Rjostler</td>\n",
       "      <td>Book</td>\n",
       "      <td>1356912000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0.1  Unnamed: 0        asin  helpful  rating  \\\n",
       "0             0       11539  B0033UV8HI  [8, 10]       3   \n",
       "1             1        5957  B002HJV4DE   [1, 1]       5   \n",
       "2             2        9146  B002ZG96I4   [0, 0]       3   \n",
       "3             3        7038  B002QHWOEU   [1, 3]       3   \n",
       "4             4        1776  B001A06VJ8   [0, 1]       4   \n",
       "\n",
       "                                          reviewText   reviewTime  \\\n",
       "0  Jace Rankin may be short, but he's nothing to ...   09 2, 2010   \n",
       "1  Great short read.  I didn't want to put it dow...   10 8, 2013   \n",
       "2  I'll start by saying this is the first of four...  04 11, 2014   \n",
       "3  Aggie is Angela Lansbury who carries pocketboo...   07 5, 2014   \n",
       "4  I did not expect this type of book to be in li...  12 31, 2012   \n",
       "\n",
       "       reviewerID  reviewerName                   summary  unixReviewTime  \n",
       "0  A3HHXRELK8BHQG        Ridley  Entertaining But Average      1283385600  \n",
       "1  A2RGNZ0TRF578I  Holly Butler   Terrific menage scenes!      1381190400  \n",
       "2  A3S0H2HV6U1I7F       Merissa          Snapdragon Alley      1397174400  \n",
       "3   AC4OQW3GZ919J    Cleargrace    very light murder cozy      1404518400  \n",
       "4  A3C9V987IQHOQD      Rjostler                      Book      1356912000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "import pandas as pd\n",
    "data = pd.read_csv('Data/all_kindle_review.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "29e507c5-35ca-4e1c-b535-08cc8ff1d91d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 11)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27a5ca9e-f101-4ce1-85f5-9cdad019395f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[['reviewText','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6631f49a-68cf-4bbd-94b1-e8cce1208243",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ffd37a0-40d9-4530-8b46-7dc1ada2506d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jace Rankin may be short, but he's nothing to ...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Great short read.  I didn't want to put it dow...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I'll start by saying this is the first of four...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aggie is Angela Lansbury who carries pocketboo...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I did not expect this type of book to be in li...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  Jace Rankin may be short, but he's nothing to ...       3\n",
       "1  Great short read.  I didn't want to put it dow...       5\n",
       "2  I'll start by saying this is the first of four...       3\n",
       "3  Aggie is Angela Lansbury who carries pocketboo...       3\n",
       "4  I did not expect this type of book to be in li...       4"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8888a716-f617-4941-b44b-e8c548ed7dd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "reviewText    0\n",
       "rating        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check missing values\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "29e63a0d-368e-4196-a3ba-624ced97ad88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 5, 4, 2, 1], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rating'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e6854fb0-45b8-437a-b698-9c7aac112ea7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "5    3000\n",
       "4    3000\n",
       "3    2000\n",
       "2    2000\n",
       "1    2000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['rating'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efed5006-0a30-4fec-84ba-300e6541b7de",
   "metadata": {},
   "source": [
    "### Great!!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef2f7ad0-b1a3-449b-a403-d8dabaf0c89c",
   "metadata": {},
   "source": [
    "## 1. Preprocessing and cleaning the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2518ac4b-61ee-42c2-ba49-7dfdf9535d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Positive review - 1 and Negative review - 0\n",
    "data['rating'] = data['rating'].apply(lambda x :0 if x<3 else 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "320e47b2-96ec-4ebd-b9f0-3b782a597a3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rating.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1bd40065-324c-413d-a34e-246fd8b3cb3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rating\n",
       "1    8000\n",
       "0    4000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.rating.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62f31cea-5c1e-4134-9fd8-271a227a2f6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.1 Lower case all the data\n",
    "data[\"reviewText\"] = data['reviewText'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e5f51e44-4b72-4c52-8d37-af327d05238d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.2 Removing all the  special characters\n",
    "import re\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: re.sub('[^a-z A-Z 0-9]+',\"\",x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85531508-19ff-4287-9798-e876412ff8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.3 Removing the stopwords\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "# nltk.download('stopwords')\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: \" \".join([y for y in x.split() if y not in stopwords.words('english')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "572eae3b-3645-4a47-9005-a0b6852a9b9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.4 Removing urls\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: re.sub(r\"(http|ftp|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=%&:/~+#-]*[\\w@?^=%&/~+#-])?\",\"\",str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4f2b4d52-6299-44f7-864b-29041430a44a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.5 Removing html tags\n",
    "from bs4 import BeautifulSoup\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: BeautifulSoup(x, 'html.parser').get_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "20c4d4b7-a006-4c52-97ed-d1f94bd56f4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        jace rankin may short hes nothing mess man hau...\n",
       "1        great short read didnt want put read one sitti...\n",
       "2        ill start saying first four books wasnt expect...\n",
       "3        aggie angela lansbury carries pocketbooks inst...\n",
       "4        expect type book library pleased find price right\n",
       "                               ...                        \n",
       "11995    valentine cupid vampire jena ian another vampi...\n",
       "11996    read seven books series apocalypticadventure o...\n",
       "11997    book really wasnt cuppa situation man capturin...\n",
       "11998    tried use charge kindle didnt even register ch...\n",
       "11999    taking instruction look often hidden world sex...\n",
       "Name: reviewText, Length: 12000, dtype: object"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "29f462c1-9a82-4b34-8107-81a267446ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_data = pd.read_csv('data/all_kindle_review.csv')\n",
    "original_data = original_data[['reviewText','rating']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "97ddb432-2bb3-44bd-ad48-7ee844b7d5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Jace Rankin may be short, but he's nothing to ...\n",
       "1        Great short read.  I didn't want to put it dow...\n",
       "2        I'll start by saying this is the first of four...\n",
       "3        Aggie is Angela Lansbury who carries pocketboo...\n",
       "4        I did not expect this type of book to be in li...\n",
       "                               ...                        \n",
       "11995    Valentine cupid is a vampire- Jena and Ian ano...\n",
       "11996    I have read all seven books in this series. Ap...\n",
       "11997    This book really just wasn't my cuppa.  The si...\n",
       "11998    tried to use it to charge my kindle, it didn't...\n",
       "11999    Taking Instruction is a look into the often hi...\n",
       "Name: reviewText, Length: 12000, dtype: object"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_data['reviewText']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c8d0c820-e0ef-4524-8e5d-e1fc8d059ce0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(oroginal_data) == len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d51ce3e2-e2df-4df8-ab39-1ce637e5ae5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.6 Apply lemmatization\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "def lemmatize_words(text):\n",
    "    return \" \".join([lemmatizer.lemmatize(word,pos='v') for word in text.split()])\n",
    "\n",
    "data['reviewText'] = data['reviewText'].apply(lambda x: lemmatize_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "60fe5c4e-fc24-44ce-983c-ae26ec698e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewText</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>jace rankin may short he nothing mess man haul...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>great short read didnt want put read one sit s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ill start say first four book wasnt expect 34c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aggie angela lansbury carry pocketbook instead...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>expect type book library please find price right</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          reviewText  rating\n",
       "0  jace rankin may short he nothing mess man haul...       1\n",
       "1  great short read didnt want put read one sit s...       1\n",
       "2  ill start say first four book wasnt expect 34c...       1\n",
       "3  aggie angela lansbury carry pocketbook instead...       1\n",
       "4   expect type book library please find price right       1"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc967437-cca8-450b-8893-010669156421",
   "metadata": {},
   "source": [
    "## 2. Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c6b94e2c-92c9-4dfa-8a32-a0cf2f2bae75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.1 Split the data into X and y\n",
    "X = data['reviewText']\n",
    "y = data['rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "9e188b32-72a0-48a3-b88b-197e7681672d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.2 train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b8ce646e-929b-4b73-955a-be7c2e653771",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9182     look forward book come double space every para...\n",
       "11091    already own book spouse forget already part li...\n",
       "6428     cool forget request rate come make mine unreli...\n",
       "288      short short story basically scene party one ni...\n",
       "2626     secret service agent secrests even longer serv...\n",
       "                               ...                        \n",
       "11964    download book read review usually read preview...\n",
       "5191     far one hottest book ive ever get hand ondont ...\n",
       "5390     even though book free reservation base majorit...\n",
       "860      little mushy 34must take care woman folk34 cha...\n",
       "7270     book good good set charaterswith background le...\n",
       "Name: reviewText, Length: 9600, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "97f72105-31ff-478e-b92f-cf3c99dd1683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9182     1\n",
       "11091    0\n",
       "6428     1\n",
       "288      0\n",
       "2626     1\n",
       "        ..\n",
       "11964    0\n",
       "5191     1\n",
       "5390     0\n",
       "860      1\n",
       "7270     1\n",
       "Name: rating, Length: 9600, dtype: int64"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "a9cb9b1f-5fc8-4ac2-9689-e49a4c6ea53e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600,)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f5e79a20-a584-49c7-a0f4-d0732244a61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600,)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a539ad38-3f89-4c5a-b00a-6345ac4f2a22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1935         really great read wish would hope find author\n",
       "6494     nope try cant read take greatest delight delet...\n",
       "1720     story line drug like book much mystery fan wou...\n",
       "9120     read several angel book one work didnt really ...\n",
       "360      possibly worst book ever read begin positively...\n",
       "                               ...                        \n",
       "1195     enjoy read think fan humorous must err use lik...\n",
       "11877    pleasantly surprise book enjoy m dubois tell s...\n",
       "5421     love best friend since 15 year old 30 he serve...\n",
       "3855     fascinate book enough twist turn keep read lon...\n",
       "4414     plot note publisher blurb publisher make fun o...\n",
       "Name: reviewText, Length: 2400, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "8a6b500b-a7b7-440a-902e-4b9f7ab4ea88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1935     1\n",
       "6494     0\n",
       "1720     0\n",
       "9120     0\n",
       "360      0\n",
       "        ..\n",
       "1195     1\n",
       "11877    1\n",
       "5421     1\n",
       "3855     1\n",
       "4414     1\n",
       "Name: rating, Length: 2400, dtype: int64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "cb8cc76a-b907-4172-8289-61b6b58535c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400,)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3385cbec-33d1-4c7c-964d-55d0c49537a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2400,)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0bd031-8142-4359-849e-9aba02797fac",
   "metadata": {},
   "source": [
    "## 3. Bag of Word ,TF-IDF and Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "1d360d08-7a19-4b83-8559-8d6320b0dab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1. Applying Bag of word\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "bow = CountVectorizer()\n",
    "X_train_bow = bow.fit_transform(X_train).toarray()\n",
    "X_test_bow = bow.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ab6b0b98-66a8-4003-9238-9e59d172b258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2. Applying tfidf \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "X_train_tfidf = tfidf.fit_transform(X_train).toarray()\n",
    "X_test_tfidf = tfidf.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1a8ec7cc-c68c-4dbd-8fe8-61afe7cbab15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_bow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "1e187250-3d37-4294-be44-d8f864169ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fd07018d-ce86-43c1-8877-c6c6ca252c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to C:\\Users\\Pavilion\\OneDrive\\De\n",
      "[nltk_data]     sktop\\UdemyMLCourse\\venv\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_train_wv: (9600, 100)\n",
      "Shape of X_test_wv: (2400, 100)\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Download the necessary NLTK data files\n",
    "nltk.download('punkt')\n",
    "\n",
    "# Define the tokenization function\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())  # Convert to lowercase to maintain consistency\n",
    "\n",
    "# Apply tokenization to train and test data\n",
    "X_train_tokenized = X_train.apply(tokenize)\n",
    "X_test_tokenized = X_test.apply(tokenize)\n",
    "\n",
    "# Train the Word2Vec model on the tokenized data\n",
    "sentences = X_train_tokenized.tolist()  # Convert tokenized data to list of lists\n",
    "wv = Word2Vec(sentences, vector_size=100, window=5, min_count=2, sg=0)\n",
    "\n",
    "# Define function to get average vector\n",
    "def get_average_vector(tokens, model):\n",
    "    vectors = [model.wv[token] for token in tokens if token in model.wv]\n",
    "    if len(vectors) == 0:\n",
    "        return np.zeros(model.vector_size)\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "# Extract features for training and test data\n",
    "X_train_wv = np.array(X_train_tokenized.apply(lambda tokens: get_average_vector(tokens, wv)).tolist())\n",
    "X_test_wv = np.array(X_test_tokenized.apply(lambda tokens: get_average_vector(tokens, wv)).tolist())\n",
    "\n",
    "print(f\"Shape of X_train_wv: {X_train_wv.shape}\")\n",
    "print(f\"Shape of X_test_wv: {X_test_wv.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "381c31b1-ad90-4272-a3ce-b55273bc64b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9600, 100)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_wv.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb51303f-2e4e-41c5-a668-b8dd7a48dc99",
   "metadata": {},
   "source": [
    "## 4. Applying Machine Learning Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "704d0ca3-e344-4189-8b99-f5dc2ebbbf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1. Applying Gaussian Naive Bayes algorithm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_model_bow = GaussianNB().fit(X_train_bow,y_train)\n",
    "nb_model_tfidf = GaussianNB().fit(X_train_tfidf,y_train)\n",
    "nb_model_wv = GaussianNB().fit(X_train_wv,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a853c34b-5237-46a3-a6de-bdc1602386dc",
   "metadata": {},
   "source": [
    "# 5. Evaluation and Performance Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "64c35039-1ffd-4231-bb11-acca9fb2a3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy BOW : 57.21\n",
      "Classification Report BOW :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.65      0.50       803\n",
      "           1       0.75      0.53      0.62      1597\n",
      "\n",
      "    accuracy                           0.57      2400\n",
      "   macro avg       0.58      0.59      0.56      2400\n",
      "weighted avg       0.64      0.57      0.58      2400\n",
      "\n",
      "Confusion Matrix BOW:\n",
      "[[521 282]\n",
      " [745 852]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy TF-IDF : 57.54\n",
      "Classification Report TF-IDF :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.63      0.50       803\n",
      "           1       0.75      0.55      0.63      1597\n",
      "\n",
      "    accuracy                           0.58      2400\n",
      "   macro avg       0.58      0.59      0.57      2400\n",
      "weighted avg       0.63      0.58      0.59      2400\n",
      "\n",
      "Confusion Matrix TF-IDF:\n",
      "[[507 296]\n",
      " [723 874]]\n",
      "\n",
      "\n",
      "\n",
      "Accuracy Word2Vec : 71.25\n",
      "Classification Report Word2Vec :\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.71      0.62       803\n",
      "           1       0.83      0.72      0.77      1597\n",
      "\n",
      "    accuracy                           0.71      2400\n",
      "   macro avg       0.69      0.71      0.69      2400\n",
      "weighted avg       0.74      0.71      0.72      2400\n",
      "\n",
      "Confusion Matrix Word2Vec:\n",
      "[[ 567  236]\n",
      " [ 454 1143]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix,accuracy_score,classification_report\n",
    "\n",
    "# Predict with X_test\n",
    "y_pred_bow = nb_model_bow.predict(X_test_bow)\n",
    "y_pred_tfidf = nb_model_tfidf.predict(X_test_tfidf)\n",
    "y_pred_wv = nb_model_wv.predict(X_test_wv)\n",
    "\n",
    "print(f\"Accuracy BOW : {accuracy_score(y_test,y_pred_bow)*100:.2f}\")\n",
    "print(f\"Classification Report BOW :\\n{classification_report(y_test,y_pred_bow)}\")\n",
    "print(f\"Confusion Matrix BOW:\\n{confusion_matrix(y_test,y_pred_bow)}\")\n",
    "print('\\n\\n')\n",
    "\n",
    "print(f\"Accuracy TF-IDF : {accuracy_score(y_test,y_pred_tfidf)*100:.2f}\")\n",
    "print(f\"Classification Report TF-IDF :\\n{classification_report(y_test,y_pred_tfidf)}\")\n",
    "print(f\"Confusion Matrix TF-IDF:\\n{confusion_matrix(y_test,y_pred_tfidf)}\")\n",
    "print('\\n\\n')\n",
    "\n",
    "print(f\"Accuracy Word2Vec : {accuracy_score(y_test,y_pred_wv)*100:.2f}\")\n",
    "print(f\"Classification Report Word2Vec :\\n{classification_report(y_test,y_pred_wv)}\")\n",
    "print(f\"Confusion Matrix Word2Vec:\\n{confusion_matrix(y_test,y_pred_wv)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f208b6e5-332d-40ca-ad4b-164f7442d0f3",
   "metadata": {},
   "source": [
    "# **- - - - - - - - - -  * - - - - - - - - - -**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3636e1e-3ff4-4e11-9cc4-108290251d9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9b22ea-2669-43fd-a7ea-058ca95863e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
